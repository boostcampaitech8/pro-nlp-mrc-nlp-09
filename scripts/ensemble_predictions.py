"""
ì•™ìƒë¸” ìŠ¤í¬ë¦½íŠ¸: nbest_predictions ê¸°ë°˜ í…ìŠ¤íŠ¸ ë ˆë²¨ score voting

ê¸°ëŠ¥:
- ì—¬ëŸ¬ ëª¨ë¸ì˜ nbest_predictions JSON íŒŒì¼ì„ ì…ë ¥ë°›ìŒ
- ì •ê·œí™”ëœ answer textë¥¼ ê¸°ì¤€ìœ¼ë¡œ score voting
- ìµœì¢… predictionsì„ TSV í¬ë§·ìœ¼ë¡œ ì €ì¥ (ë¦¬ë”ë³´ë“œ ì œì¶œìš©)

ì‚¬ìš© ì˜ˆì‹œ:
python scripts/ensemble_predictions.py \\
  --nbest_paths outputs/exp1/nbest_predictions.json outputs/exp2/nbest_predictions.json \\
  --output_path outputs/ensemble/ens_test_pred.csv \\
  --weights 0.4 0.6 \\
  --score_key probability
"""

import json
import argparse
import logging
from typing import Dict, List, Optional, Tuple
from collections import defaultdict
import csv
import re

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


def normalize_answer(text: str) -> str:
    """
    Answer ì •ê·œí™” (ê³µë°±/êµ¬ë‘ì  ì œê±°, ì†Œë¬¸ìí™”)

    ì •ê·œí™”ëœ textê°€ keyë¡œ ì‚¬ìš©ë˜ì–´ ê°™ì€ answerë¥¼ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.

    Args:
        text: ì›ë³¸ answer text

    Returns:
        ì •ê·œí™”ëœ text
    """
    # ì†Œë¬¸ìí™”
    text = text.lower()
    # êµ¬ë‘ì  ì œê±° (ê³µë°± ì œì™¸)
    text = re.sub(r"[^\w\s]", "", text)
    # ì—°ì† ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
    text = re.sub(r"\s+", " ", text).strip()
    return text


def load_nbest(path: str) -> Dict[str, List[Dict]]:
    """
    nbest_predictions.json ë¡œë“œ

    Format: {
        "qid1": [
            {"text": "answer1", "probability": 0.9},
            {"text": "answer2", "probability": 0.05},
            ...
        ],
        ...
    }

    Args:
        path: JSON íŒŒì¼ ê²½ë¡œ

    Returns:
        {qid: [{"text": ..., "probability"/"score": ...}]}
    """
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # ë‹¤ì–‘í•œ í¬ë§· ì§€ì› (nbest_predictionsì´ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” dictì¼ ìˆ˜ ìˆìŒ)
    if isinstance(data, list):
        # List of dicts: [{"id": qid, "text": answer, ...}]
        result = defaultdict(list)
        for item in data:
            qid = item.get("id")
            if qid:
                result[qid].append(item)
        return dict(result)
    else:
        # Dict of qid -> list
        return data


def ensemble_nbest(
    nbest_paths: List[str],
    weights: Optional[List[float]] = None,
    score_key: str = "probability",
) -> Dict[str, str]:
    """
    ì•™ìƒë¸” ë¡œì§: ì •ê·œí™”ëœ answer ê¸°ì¤€ score voting

    Args:
        nbest_paths: nbest_predictions.json íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        weights: ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ (Noneì´ë©´ ê· ë“±)
        score_key: score í•„ë“œëª… ("probability" or "score")

    Returns:
        {qid: best_answer_text}
    """
    num_models = len(nbest_paths)

    if weights is None:
        weights = [1.0 / num_models] * num_models
    else:
        weights = [w / sum(weights) for w in weights]  # ì •ê·œí™”

    logger.info(f"ğŸ¯ Ensemble with {num_models} models, weights: {weights}")
    logger.info(f"   Score key: {score_key}")

    # ëª¨ë“  nbest íŒŒì¼ ë¡œë“œ
    nbest_list = []
    for path in nbest_paths:
        logger.info(f"ğŸ“– Loading {path}...")
        nbest_data = load_nbest(path)
        nbest_list.append(nbest_data)

    # ëª¨ë“  question ID ìˆ˜ì§‘
    all_qids = set()
    for nbest_data in nbest_list:
        all_qids.update(nbest_data.keys())

    logger.info(f"ğŸ“Š Total questions: {len(all_qids)}")

    # ê° questionì— ëŒ€í•´ ì•™ìƒë¸” ìˆ˜í–‰
    ensemble_predictions = {}

    for qid in all_qids:
        # ì •ê·œí™”ëœ answer -> ëˆ„ì  score
        answer_scores = defaultdict(float)
        # ì •ê·œí™”ëœ answer -> (ìµœê³  score, ì›ë³¸ text) - ê°€ì¥ ë†’ì€ scoreì˜ ì›ë³¸ ë³´ì¡´
        answer_best_original = {}

        for model_idx, nbest_data in enumerate(nbest_list):
            weight = weights[model_idx]

            if qid not in nbest_data:
                logger.warning(f"âš ï¸ qid {qid} not found in model {model_idx}")
                continue

            candidates = nbest_data[qid]
            if not candidates:
                continue

            # Top candidateì—ì„œë§Œ score ê°€ì ¸ì˜¤ê¸° (ë˜ëŠ” ëª¨ë“  í›„ë³´ - ì—¬ê¸°ì„œëŠ” top 3ê¹Œì§€ ì²˜ë¦¬)
            for candidate in candidates[:3]:  # top-3 í›„ë³´ë§Œ ê³ ë ¤
                text = candidate.get("text", "")
                score = candidate.get(score_key, 0.0)

                if not text:
                    continue

                normalized = normalize_answer(text)
                answer_scores[normalized] += weight * score
                answer_original[normalized] = text

        # ê°€ì¥ ë†’ì€ scoreë¥¼ ê°€ì§„ answer ì„ íƒ
        if answer_scores:
            best_normalized = max(answer_scores, key=answer_scores.get)
            best_answer = answer_original[best_normalized]
            ensemble_predictions[qid] = best_answer
        else:
            logger.warning(f"âš ï¸ No valid candidates for qid {qid}")
            ensemble_predictions[qid] = ""

    logger.info(f"âœ… Ensemble complete: {len(ensemble_predictions)} predictions")
    return ensemble_predictions


def save_predictions_csv(predictions: Dict[str, str], output_path: str):
    """
    Predictionsì„ TSV í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ë¦¬ë”ë³´ë“œ ì œì¶œìš©)

    Format:
    id\tanswer
    qid1\tanswer1
    qid2\tanswer2

    Args:
        predictions: {qid: answer} dict
        output_path: ì €ì¥ ê²½ë¡œ
    """
    import os

    os.makedirs(
        os.path.dirname(output_path) if os.path.dirname(output_path) else ".",
        exist_ok=True,
    )

    with open(output_path, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f, delimiter="\t")
        writer.writerow(["id", "answer"])  # í—¤ë”
        for qid, answer in sorted(predictions.items()):
            writer.writerow([qid, answer])

    logger.info(f"ğŸ’¾ Predictions saved to {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="ì•™ìƒë¸”: nbest_predictions ê¸°ë°˜ í…ìŠ¤íŠ¸ ë ˆë²¨ score voting"
    )

    parser.add_argument(
        "--nbest_paths",
        nargs="+",
        required=True,
        help="nbest_predictions.json íŒŒì¼ ê²½ë¡œë“¤ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)",
    )
    parser.add_argument(
        "--output_path",
        type=str,
        required=True,
        help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (TSV í¬ë§·)",
    )
    parser.add_argument(
        "--weights",
        nargs="+",
        type=float,
        default=None,
        help="ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ (ë¯¸ì§€ì • ì‹œ ê· ë“±)",
    )
    parser.add_argument(
        "--score_key",
        type=str,
        choices=["probability", "score"],
        default="probability",
        help="ì‚¬ìš©í•  score í•„ë“œëª…",
    )

    args = parser.parse_args()

    # Validation
    if args.weights and len(args.weights) != len(args.nbest_paths):
        raise ValueError(
            f"weights ê°œìˆ˜({len(args.weights)}) != nbest_paths ê°œìˆ˜({len(args.nbest_paths)})"
        )

    # ì•™ìƒë¸” ìˆ˜í–‰
    ensemble_results = ensemble_nbest(
        nbest_paths=args.nbest_paths,
        weights=args.weights,
        score_key=args.score_key,
    )

    # ê²°ê³¼ ì €ì¥
    save_predictions_csv(ensemble_results, args.output_path)

    logger.info("ğŸ‰ Ensemble complete!")


if __name__ == "__main__":
    main()
