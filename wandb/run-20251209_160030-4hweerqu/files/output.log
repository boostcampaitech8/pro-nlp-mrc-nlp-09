 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                      | 499/1497 [08:25<15:03,  1.10it/s]/data/ephemeral/home/shared/.venv/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:476: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.
{'loss': 5.9967, 'grad_norm': 10.151673316955566, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 5.2513, 'grad_norm': 9.394915580749512, 'learning_rate': 9.8e-06, 'epoch': 0.1}
{'loss': 2.9925, 'grad_norm': 28.48796844482422, 'learning_rate': 1.98e-05, 'epoch': 0.2}
{'loss': 1.4127, 'grad_norm': 31.52080726623535, 'learning_rate': 2.98e-05, 'epoch': 0.3}
{'loss': 1.0749, 'grad_norm': 23.734561920166016, 'learning_rate': 2.89086859688196e-05, 'epoch': 0.4}
{'loss': 1.068, 'grad_norm': 19.2311954498291, 'learning_rate': 2.779510022271715e-05, 'epoch': 0.5}
{'loss': 0.9155, 'grad_norm': 20.122020721435547, 'learning_rate': 2.66815144766147e-05, 'epoch': 0.6}
{'loss': 0.8188, 'grad_norm': 21.834476470947266, 'learning_rate': 2.5567928730512252e-05, 'epoch': 0.7}
{'loss': 0.8006, 'grad_norm': 19.411746978759766, 'learning_rate': 2.4454342984409798e-05, 'epoch': 0.8}
{'loss': 0.7858, 'grad_norm': 19.015100479125977, 'learning_rate': 2.334075723830735e-05, 'epoch': 0.9}
  warnings.warn(
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:01<00:00, 199.26it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:01<00:00, 196.05it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:01<00:00, 196.45it/s]
{'eval_exact_match': 62.916666666666664, 'eval_f1': 72.29922161172163, 'epoch': 1.0}
{'loss': 0.7092, 'grad_norm': 22.102867126464844, 'learning_rate': 2.22271714922049e-05, 'epoch': 1.0}
{'loss': 0.3744, 'grad_norm': 33.30931091308594, 'learning_rate': 2.1113585746102452e-05, 'epoch': 1.1}
{'loss': 0.4657, 'grad_norm': 22.69951057434082, 'learning_rate': 1.9999999999999998e-05, 'epoch': 1.2}
{'loss': 0.4904, 'grad_norm': 12.760254859924316, 'learning_rate': 1.888641425389755e-05, 'epoch': 1.3}
{'loss': 0.3811, 'grad_norm': 8.488300323486328, 'learning_rate': 1.77728285077951e-05, 'epoch': 1.4}
{'loss': 0.4472, 'grad_norm': 17.675275802612305, 'learning_rate': 1.6659242761692653e-05, 'epoch': 1.5}
{'loss': 0.3899, 'grad_norm': 20.608314514160156, 'learning_rate': 1.55456570155902e-05, 'epoch': 1.6}
{'loss': 0.4357, 'grad_norm': 15.959683418273926, 'learning_rate': 1.4432071269487751e-05, 'epoch': 1.7}
{'loss': 0.3687, 'grad_norm': 12.383118629455566, 'learning_rate': 1.33184855233853e-05, 'epoch': 1.8}
{'loss': 0.3793, 'grad_norm': 5.995055675506592, 'learning_rate': 1.2204899777282852e-05, 'epoch': 1.9}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1497/1497 [25:59<00:00,  1.04s/it]
{'eval_exact_match': 69.16666666666667, 'eval_f1': 76.76510179635183, 'epoch': 2.0}
{'loss': 0.3123, 'grad_norm': 12.987327575683594, 'learning_rate': 1.10913140311804e-05, 'epoch': 2.0}
{'loss': 0.1305, 'grad_norm': 48.24326705932617, 'learning_rate': 9.977728285077952e-06, 'epoch': 2.1}
{'loss': 0.1459, 'grad_norm': 33.995059967041016, 'learning_rate': 8.864142538975501e-06, 'epoch': 2.2}
{'loss': 0.1255, 'grad_norm': 16.917945861816406, 'learning_rate': 7.750556792873052e-06, 'epoch': 2.3}
{'loss': 0.1592, 'grad_norm': 6.595480918884277, 'learning_rate': 6.636971046770601e-06, 'epoch': 2.4}
{'loss': 0.1251, 'grad_norm': 0.2521471679210663, 'learning_rate': 5.523385300668151e-06, 'epoch': 2.51}
{'loss': 0.1617, 'grad_norm': 0.551960289478302, 'learning_rate': 4.4097995545657015e-06, 'epoch': 2.61}
{'loss': 0.1654, 'grad_norm': 22.230127334594727, 'learning_rate': 3.2962138084632516e-06, 'epoch': 2.71}
{'loss': 0.1053, 'grad_norm': 3.3956894874572754, 'learning_rate': 2.1826280623608017e-06, 'epoch': 2.81}
{'loss': 0.1483, 'grad_norm': 10.77697467803955, 'learning_rate': 1.0690423162583519e-06, 'epoch': 2.91}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:01<00:00, 199.00it/s]
{'eval_exact_match': 66.25, 'eval_f1': 75.40540940540943, 'epoch': 3.0}
{'train_runtime': 1565.9621, 'train_samples_per_second': 15.284, 'train_steps_per_second': 0.956, 'train_loss': 0.7112207001817967, 'epoch': 3.0}
âœ… Training metrics saved to ./outputs/sehun/roberta_base/training_metrics.json
âœ… Epoch summary saved to ./outputs/sehun/roberta_base/epoch_summary.json and ./outputs/sehun/roberta_base/epoch_summary.md
âœ… Training metrics plot saved to ./outputs/sehun/roberta_base/training_metrics.png
16:26:31 | INFO     | Training completed.
16:26:31 | INFO     | Saving model to ./outputs/sehun/roberta_base
16:26:31 | INFO     | ìµœì¢… í›ˆë ¨ ê²°ê³¼: {'train_runtime': 1565.9621, 'train_samples_per_second': 15.284, 'train_steps_per_second': 0.956, 'total_flos': 1.6670754862193664e+16, 'train_loss': 0.7112207001817967, 'epoch': 3.0}
16:26:34 | INFO     | âœ… Best checkpoint saved: ./outputs/sehun/roberta_base/checkpoint-998
16:26:34 | INFO     |    Best metric (exact_match): 69.16666666666667
***** train metrics *****
  epoch                    =        3.0
  total_flos               = 15525850GF
  train_loss               =     0.7112
  train_runtime            = 0:26:05.96
  train_samples            =       7978
  train_samples_per_second =     15.284
  train_steps_per_second   =      0.956
16:26:34 | INFO     | ***** Train results *****
16:26:34 | INFO     |   epoch = 3.0
16:26:34 | INFO     |   total_flos = 1.6670754862193664e+16
16:26:34 | INFO     |   train_loss = 0.7112207001817967
16:26:34 | INFO     |   train_runtime = 1565.9621
16:26:34 | INFO     |   train_samples = 7978
16:26:34 | INFO     |   train_samples_per_second = 15.284
16:26:34 | INFO     |   train_steps_per_second = 0.956
16:26:34 | INFO     | Running final evaluation on validation set (474 examples)
16:26:34 | INFO     | Best metric: 69.16666666666667
16:26:34 | INFO     | Best model checkpoint: ./outputs/sehun/roberta_base/checkpoint-998
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.40it/s]
***** eval metrics *****
  epoch            =     3.0
  eval_exact_match = 69.1667
  eval_f1          = 76.7651
  eval_samples     =     474

================================================================================
ðŸ“Š TRAINING SUMMARY
================================================================================

ðŸ“‰ Training Loss:
   - Final: 0.1483 (Epoch 2.91, Step 1450)
   - Best: 0.1053 (Epoch 2.81, Step 1400)

ðŸ“Š Validation Metrics:

ðŸ† Best Exact Match: 69.17
   - Epoch: 2.00
   - Step: 998
   - F1: 76.77

ðŸ† Best F1 Score: 76.77
   - Epoch: 2.00
   - Step: 998
   - EM: 69.17

ðŸ“ˆ Final Validation Metrics (Epoch 3.00):
   - EM: 69.17
   - F1: 76.77

ðŸ’¡ Test ë©”íŠ¸ë¦­ì€ inference í›„ì— í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
================================================================================

16:26:44 | INFO     | ================================================================================
16:26:44 | INFO     | Running final performance evaluation on all splits...
16:26:44 | INFO     | ================================================================================
16:26:46 | INFO     | Evaluating on TRAIN set...
Preparing train features for evaluation (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3952/3952 [00:02<00:00, 1588.83 examples/s]
/data/ephemeral/home/shared/.venv/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:476: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3952/3952 [00:20<00:00, 195.39it/s]
/data/ephemeral/home/shared/.venv/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:476: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.
âœ… Predictions saved to ./outputs/sehun/roberta_base/train_predictions.json
âœ… Loaded confidence data from ./outputs/sehun/roberta_base/train_confidence.csv
âœ… Detailed results saved to ./outputs/sehun/roberta_base/train_detailed_results.json
16:30:16 | INFO     | Evaluating on VALIDATION set (gold context)...
  warnings.warn(
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:01<00:00, 196.51it/s]
265it [03:41,  1.20it/s]â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 233/240 [00:01<00:00, 195.67it/s]
âœ… Predictions saved to ./outputs/sehun/roberta_base/val_predictions.json
âœ… Loaded confidence data from ./outputs/sehun/roberta_base/val_confidence.csv
âœ… Detailed results saved to ./outputs/sehun/roberta_base/val_detailed_results.json
16:30:30 | INFO     | âœ… Validation predictions (gold context) saved to ./outputs/sehun/roberta_base/eval_pred_gold.csv
16:30:30 | INFO     | âœ… Validation labels saved to ./outputs/sehun/roberta_base/eval_labels.json
âœ… Final evaluation summary saved to ./outputs/sehun/roberta_base/final_evaluation_summary.json

================================================================================
ðŸŽ¯ FINAL MODEL PERFORMANCE SUMMARY
================================================================================

ðŸ“˜ Train Performance:
  ðŸ“Š Exact Match: 92.51
  ðŸ“Š F1 Score: 94.75
  ðŸ“ Total Samples: 3952
  ðŸ” With Retrieval: No

ðŸ“— Validation Performance (Direct Context):
  ðŸ“Š Exact Match: 69.17
  ðŸ“Š F1 Score: 76.77
  ðŸ“ Total Samples: 240
  ðŸ” With Retrieval: No

ðŸ“™ Validation Performance (With Retrieval): Not evaluated

ðŸ“• Test Performance: Not evaluated
================================================================================

16:30:30 | INFO     | âœ… Final performance evaluation completed successfully
