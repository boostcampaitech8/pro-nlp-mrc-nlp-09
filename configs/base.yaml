# model, data는 arguments.py에 지정된 dataclass 형식에 맞게 작성하면 됩니다. (값 미기재 시 default 값 사용)
# training은 TrainingArguments 형식에 맞게 작성하면 됩니다. (HF transformers 제공)
# base.yaml 기준으로 configs/exp/exp_name.yaml 파일을 만들고 실험별 설정을 관리하시면 됩니다.

# 모드는 스크립트에서 강제 세팅 (train.py: do_train=True, do_eval=True)
# do_train / do_eval / do_predict 여기서 설정 불필요

##################################
# --- model (ModelArguments) ---
##################################
model_name_or_path: klue/bert-base  # 사전학습 모델 또는 checkpoint 경로
# config_name: null         # 모델과 동일하면 생략 가능
# tokenizer_name: null      # 모델과 동일하면 생략 가능

# [Inference 전용 설정]
use_trained_model: true     # inference 시 output_dir에서 best checkpoint 자동 탐색
#                           # false로 설정하면 model_name_or_path의 pretrained model 직접 사용


##################################
# --- data (DataTrainingArguments) ---
##################################
train_dataset_name: ./data/train_dataset     # train에서 사용하는 데이터셋 (train + validation split 포함)
infer_dataset_name: ./data/test_dataset      # test split 데이터셋 (제출용, 정답 없음)

overwrite_cache: false
preprocessing_num_workers: 4
max_seq_length: 384
pad_to_max_length: false
doc_stride: 128
max_answer_length: 30

# retrieval 관련
eval_retrieval: true
num_clusters:
top_k_retrieval: 10
use_faiss: false

# [Inference 전용 설정]
inference_split: test        # 추론할 데이터 선택 (train/validation/test)
                             # - train: train_dataset의 train split 사용 (do_eval + do_predict)
                             # - validation: train_dataset의 validation split 사용 (do_eval + do_predict)
                             # - test: infer_dataset_name 사용 (do_predict만, 제출용, 기본값)

##################################
# --- training (TrainingArguments) ---
##################################
output_dir: ./outputs/{username}/{exp_name}  # {username} 부분을 본인 이름으로 변경 권장
num_train_epochs: 5
per_device_train_batch_size: 16          # 3952 / 16 = 247 steps/epoch
per_device_eval_batch_size: 32
learning_rate: 3.0e-5
warmup_ratio: 0.1                         # ~74 steps warmup
weight_decay: 0.01

# logging & save 전략 (247 steps/epoch 기준)
logging_steps: 50
logging_first_step: true
eval_strategy: epoch
save_strategy: epoch
save_total_limit: 2
load_best_model_at_end: true
metric_for_best_model: "exact_match"
greater_is_better: true

# 기타 설정
fp16: # 큰 모델 양자화
dataloader_num_workers: 2
gradient_accumulation_steps: 1
resume_from_checkpoint:

# wandb 관련 설정
report_to:
# report_to: wandb              # wandb 사용 시 주석 해제
# run_name: mrc-bert-base       # wandb run name

